{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVPUgOLTCdz6zM8hbeJzC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/23206-final-pose-estimation-for-swing-improvement/blob/main/Yolov7_Pose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnExzDm4PamO",
        "outputId": "525c8632-6a58-4cf4-c42d-5c89dbe8f4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1197, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n",
            "Receiving objects: 100% (1197/1197), 74.23 MiB | 23.76 MiB/s, done.\n",
            "Resolving deltas: 100% (517/517), done.\n",
            "--2023-12-12 09:42:07--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ad063dcb-fb9a-4511-b4d7-499601326cd8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231212T094207Z&X-Amz-Expires=300&X-Amz-Signature=1cb6dc21b58a6311bd17288baf4d796bfa04ba49d8cddedfd350fca3557568c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-w6-pose.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-12 09:42:07--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/ad063dcb-fb9a-4511-b4d7-499601326cd8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231212T094207Z&X-Amz-Expires=300&X-Amz-Signature=1cb6dc21b58a6311bd17288baf4d796bfa04ba49d8cddedfd350fca3557568c6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7-w6-pose.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 161114789 (154M) [application/octet-stream]\n",
            "Saving to: ‘yolov7-w6-pose.pt’\n",
            "\n",
            "yolov7-w6-pose.pt   100%[===================>] 153.65M   188MB/s    in 0.8s    \n",
            "\n",
            "2023-12-12 09:42:08 (188 MB/s) - ‘yolov7-w6-pose.pt’ saved [161114789/161114789]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import sys\n",
        "sys.path.append('/content/yolov7')\n",
        "\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import non_max_suppression_kpt\n",
        "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
        "\n",
        "import cv2\n",
        "import csv\n",
        "import os\n",
        "import math\n",
        "import datetime\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "pHJ7G_ElRNph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = 'folder'\n",
        "\n",
        "url = f\"https://github.com/Strojove-uceni/23206-final-pose-estimation-for-swing-improvement/raw/main/cropped_videos.zip\"\n",
        "!wget {url}\n",
        "!unzip cropped_videos.zip\n",
        "!rm cropped_videos.zip\n",
        "\n",
        "if input == 'file':\n",
        "  # SET AN INPUT FILE in the folder cropped_videos\n",
        "  input_file = 'cropped_videos/output_video_-M5SITXMA2Y.mp4'\n",
        "  csv_file_name = f'{os.path.splitext(input_file)[0]}.csv'\n",
        "  output_video_name = f'{os.path.splitext(input_file)[0]}_output.mp4'\n",
        "\n",
        "elif input == 'folder':\n",
        "  input_folder = 'cropped_videos'\n",
        "  output_folder_videos = 'result_videos'\n",
        "  output_folder_csv = 'result_statistics'\n",
        "  # Create output folders if they don't exist\n",
        "  os.makedirs(output_folder_videos, exist_ok=True)\n",
        "  os.makedirs(output_folder_csv, exist_ok=True)\n",
        "\n",
        "else:\n",
        "  print(\"You have just two options: 'file' or 'folder'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtdCfGTTP35n",
        "outputId": "f4c4911d-9453-4830-adf7-a7faf0ab210d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-12 09:42:20--  https://github.com/Strojove-uceni/23206-final-pose-estimation-for-swing-improvement/raw/main/cropped_videos/output_video_-M5SITXMA2Y.mp4\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Strojove-uceni/23206-final-pose-estimation-for-swing-improvement/main/cropped_videos/output_video_-M5SITXMA2Y.mp4 [following]\n",
            "--2023-12-12 09:42:20--  https://raw.githubusercontent.com/Strojove-uceni/23206-final-pose-estimation-for-swing-improvement/main/cropped_videos/output_video_-M5SITXMA2Y.mp4\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 254614 (249K) [application/octet-stream]\n",
            "Saving to: ‘output_video_-M5SITXMA2Y.mp4’\n",
            "\n",
            "output_video_-M5SIT 100%[===================>] 248.65K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-12-12 09:42:21 (5.26 MB/s) - ‘output_video_-M5SITXMA2Y.mp4’ saved [254614/254614]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# method to load the model from the downloaded weights\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def calculate_angle(a_x, a_y, b_x, b_y, c_x, c_y):\n",
        "    # Calculate the angle between three points in degrees\n",
        "    radians = math.atan2(c_y - b_y, c_x - b_x) - math.atan2(a_y - b_y, a_x - b_x)\n",
        "    angle = math.degrees(radians)\n",
        "    angle = abs(angle)\n",
        "    if angle > 180:\n",
        "        angle = 360 - angle\n",
        "    return angle\n",
        "\n",
        "def calculate_angle2(x1, y1, x2, y2, axis='x', orientation='right'):\n",
        "    if (math.sqrt((x2 - x1)**2 + (y2 - y1)**2) * x1) != 0:\n",
        "        if axis == 'x':\n",
        "            theta = math.acos((x2 - x1) * (-x1) / (math.sqrt((x2 - x1)**2 + (y2 - y1)**2) * x1))\n",
        "        elif axis == 'y':\n",
        "            theta = math.acos( (y2 -y1)*(-y1) / (math.sqrt((x2 - x1)**2 + (y2 - y1)**2 ) * y1))\n",
        "        else:\n",
        "            raise ValueError(\"Invalid axis, use 'x' or 'y'\")\n",
        "\n",
        "        if orientation == 'right':\n",
        "            angle = int(180/math.pi) * theta\n",
        "        elif orientation == 'left':\n",
        "            angle = 180 - int(180/math.pi) * theta\n",
        "        else:\n",
        "            raise ValueError(\"Invalid orientation, use 'left' or 'right'\")\n",
        "\n",
        "    else:\n",
        "        return 0  # Handle the case where x1 is zero to avoid division by zero\n",
        "\n",
        "    return angle\n",
        "\n",
        "def middle_point(a_x, a_y, b_x, b_y):\n",
        "    midpoint_x = (a_x + b_x) / 2\n",
        "    midpoint_y = (a_y + b_y) / 2\n",
        "    return midpoint_x, midpoint_y\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    model = torch.load('yolov7-w6-pose.pt', map_location=device)['model']\n",
        "    # Put in inference mode\n",
        "    model.float().eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        # half() turns predictions into float16 tensors\n",
        "        # which significantly lowers inference time\n",
        "        model.half().to(device)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "\n",
        "# method for running inference\n",
        "def run_inference(image):\n",
        "    # Resize and pad image\n",
        "    image = letterbox(image, 960, stride=64, auto=True)[0]  # shape: (567, 960, 3)\n",
        "    # Apply transforms\n",
        "    image = transforms.ToTensor()(image)  # torch.Size([3, 567, 960])\n",
        "    if torch.cuda.is_available():\n",
        "        image = image.half().to(device)\n",
        "    # Turn image into batch\n",
        "    image = image.unsqueeze(0)  # torch.Size([1, 3, 567, 960])\n",
        "    with torch.no_grad():\n",
        "        output, _ = model(image)\n",
        "    return output, image\n",
        "\n",
        "\n",
        "def save_keypoints(kpts, steps):\n",
        "    num_kpts = len(kpts) // steps\n",
        "    coords = []\n",
        "    for kid in range(num_kpts):\n",
        "        x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n",
        "        if not (x_coord % 640 == 0 or y_coord % 640 == 0):\n",
        "            if steps == 3:\n",
        "                conf = kpts[steps * kid + 2]\n",
        "                if conf < 0.5:\n",
        "                    coords.append(0)\n",
        "                    coords.append(0)\n",
        "                    continue\n",
        "        coords.append(x_coord)\n",
        "        coords.append(y_coord)\n",
        "    return coords\n",
        "\n",
        "\n",
        "# return the predictions of the model and plot the predicted skeletons over the image itself\n",
        "def draw_keypoints(output, image):\n",
        "    output = non_max_suppression_kpt(output,\n",
        "                                      0.25,  # Confidence Threshold\n",
        "                                      0.65,  # IoU Threshold\n",
        "                                      nc=model.yaml['nc'],  # Number of Classes\n",
        "                                      nkpt=model.yaml['nkpt'],  # Number of Keypoints\n",
        "                                      kpt_label=True)\n",
        "    with torch.no_grad():\n",
        "        output = output_to_keypoint(output)\n",
        "    nimg = image[0].permute(1, 2, 0) * 255\n",
        "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
        "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    all_coords = []\n",
        "    for idx in range(output.shape[0]):\n",
        "        #plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
        "        coords = save_keypoints(output[idx, 7:].T, 3)\n",
        "        all_coords.append(coords)\n",
        "    return nimg, all_coords\n",
        "\n",
        "\n",
        "def write_csv_file(video_name, coordinates):\n",
        "    if input == 'file':\n",
        "      csv_filename = video_name\n",
        "    else:\n",
        "      csv_folder = 'result_statistics'\n",
        "      os.makedirs(csv_folder, exist_ok=True)\n",
        "      csv_filename = os.path.join(csv_folder, f'{video_name}.csv')\n",
        "\n",
        "    with open(csv_filename, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Check if the file is empty (i.e., first frame) and write header accordingly\n",
        "        if os.path.getsize(csv_filename) == 0:\n",
        "            writer.writerow([\"video_timestamp\", \"shoulders_inclination\", \"hips_inclination\",\n",
        "                             \"knee_angle\", \"pelvis_angle\", \"arm_angle\",\n",
        "                             \"right_shoulder X\", \"right_shoulder Y\",\n",
        "                             \"left_shoulder X\", \"left_shoulder Y\",\n",
        "                             \"left_elbow X\", \"left_elbow Y\",\n",
        "                             \"right_wrist X\", \"right_wrist Y\",\n",
        "                             \"left_wrist X\", \"left_wrist Y\",\n",
        "                             \"nose X\", \"nose Y\",\n",
        "                             \"right_hip X\", \"right_hip Y\",\n",
        "                             \"left_hip X\", \"left_hip Y\",\n",
        "                             \"right_knee X\", \"right_knee Y\",\n",
        "                             \"left_knee X\", \"left_knee Y\",\n",
        "                             \"right_ankle X\", \"right_ankle Y\",\n",
        "                             \"left_ankle X\", \"left_ankle Y\",\n",
        "                             \"midpoint X\", \"midpoint Y\"])\n",
        "\n",
        "        writer.writerow(coordinates)\n",
        "\n",
        "\n",
        "# real-time video setting\n",
        "def pose_estimation(input_file, csv_file_name, output_video_name):\n",
        "    output_folder = 'result_videos'\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(input_file)\n",
        "    # VideoWriter for saving the video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    out = cv2.VideoWriter(output_video_name, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "    frame_number = 0\n",
        "    while cap.isOpened():\n",
        "        (ret, frame) = cap.read()\n",
        "        if ret == True:\n",
        "            frame_number += 1\n",
        "\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            output, frame = run_inference(frame)\n",
        "            frame, all_coords = draw_keypoints(output, frame)\n",
        "\n",
        "            a = 0\n",
        "            for person in all_coords:\n",
        "                # Get coordinates of specific landmarks\n",
        "                left_shoulder_x = person[10]\n",
        "                left_shoulder_y = person[11]\n",
        "                right_shoulder_x = person[12]\n",
        "                right_shoulder_y = person[13]\n",
        "                left_hip_x = person[22]\n",
        "                left_hip_y = person[23]\n",
        "                right_hip_x = person[24]\n",
        "                right_hip_y = person[25]\n",
        "                left_wrist_x = person[18]\n",
        "                left_wrist_y = person[19]\n",
        "                right_wrist_x = person[20]\n",
        "                right_wrist_y = person[21]\n",
        "                nose_x = person[0]\n",
        "                nose_y = person[1]\n",
        "                left_knee_x = person[26]\n",
        "                left_knee_y = person[27]\n",
        "                right_knee_x = person[28]\n",
        "                right_knee_y = person[29]\n",
        "                left_ankle_x = person[30]\n",
        "                left_ankle_y = person[31]\n",
        "                right_ankle_x = person[32]\n",
        "                right_ankle_y = person[33]\n",
        "                left_elbow_x = person[14]\n",
        "                left_elbow_y = person[15]\n",
        "\n",
        "                # Calculate angles\n",
        "                knee_angle = calculate_angle(left_hip_x, left_hip_y, left_knee_x, left_knee_y, left_ankle_x, left_ankle_y)\n",
        "                pelvis_angle = calculate_angle(left_ankle_x, left_ankle_y, left_hip_x, left_hip_y, right_shoulder_x, right_shoulder_y)\n",
        "                arm_angle = calculate_angle(left_wrist_x, left_wrist_y, left_elbow_x, left_elbow_y, left_shoulder_x, left_shoulder_y)\n",
        "                shoulders_inclination = calculate_angle2(right_shoulder_x, right_shoulder_y,\n",
        "                                                         left_shoulder_x, left_shoulder_y, 'x', 'left')\n",
        "                hips_inclination = calculate_angle2(left_hip_x, left_hip_y, right_hip_x, right_hip_y, 'x')\n",
        "                midpoint_x, midpoint_y = middle_point(right_ankle_x, right_ankle_y, left_ankle_x, left_ankle_y)\n",
        "                # Get the timestamp\n",
        "                fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "                video_timestamp = round(frame_number / fps)\n",
        "                video_timestamp = str(datetime.timedelta(seconds=video_timestamp))\n",
        "\n",
        "\n",
        "                # Display points\n",
        "                cv2.circle(frame, (int(right_shoulder_x), int(right_shoulder_y)), 6, (0, 255, 0), -1)\n",
        "                cv2.circle(frame, (int(left_shoulder_x), int(left_shoulder_y)), 6, (0, 255, 0), -1)\n",
        "                cv2.circle(frame, (int(right_hip_x), int(right_hip_y)), 6, (255, 255, 0), -1)\n",
        "                cv2.circle(frame, (int(left_hip_x), int(left_hip_y)), 6, (0, 150, 255), -1)\n",
        "                cv2.circle(frame, (int(right_knee_x), int(right_knee_y)), 6, (255, 0, 255), -1)\n",
        "                cv2.circle(frame, (int(left_knee_x), int(left_knee_y)), 6, (255, 0, 255), -1)\n",
        "                cv2.circle(frame, (int(left_ankle_x), int(left_ankle_y)), 6, (255, 0, 0), -1)\n",
        "                cv2.circle(frame, (int(left_wrist_x), int(left_wrist_y)), 6, (0, 255, 255), -1)\n",
        "                cv2.circle(frame, (int(nose_x), int(nose_y)), 6, (0, 0, 255), -1)\n",
        "                cv2.circle(frame, (int(left_elbow_x), int(left_elbow_y)), 6, (128, 0, 128), -1)\n",
        "                cv2.circle(frame, (int(right_ankle_x), int(right_ankle_y)), 6, (255, 0, 0), -1)\n",
        "                cv2.circle(frame, (int(midpoint_x), int(midpoint_y)), 6, (255, 255, 255), -1)\n",
        "\n",
        "                # Display angle and lines on the image\n",
        "                cv2.line(frame, (int(left_ankle_x), int(left_ankle_y)), (int(left_ankle_x), int(left_ankle_y)- 200), (255, 0, 0), 2)\n",
        "                cv2.line(frame, (int(right_ankle_x), int(right_ankle_y)), (int(right_ankle_x), int(right_ankle_y) - 200), (255, 0, 0), 2)\n",
        "\n",
        "                cv2.line(frame, (int(right_shoulder_x), int(right_shoulder_y)), (int(right_shoulder_x) + 100, int(right_shoulder_y)), (0, 255, 0), 2)\n",
        "                cv2.line(frame, (int(left_shoulder_x), int(left_shoulder_y)), (int(right_shoulder_x), int(right_shoulder_y)), (0, 255, 0), 2)\n",
        "                cv2.line(frame, (int(left_hip_x), int(left_hip_y)), (int(left_hip_x) - 100, int(left_hip_y) ), (255, 255, 0), 2)\n",
        "                cv2.line(frame, (int(left_hip_x), int(left_hip_y)), (int(right_hip_x), int(right_hip_y)), (255, 255, 0), 2)\n",
        "\n",
        "                cv2.line(frame, (int(left_hip_x), int(left_hip_y)), (int(left_knee_x), int(left_knee_y)), (255, 0, 255), 2)\n",
        "                cv2.line(frame, (int(left_knee_x), int(left_knee_y)), (int(left_ankle_x), int(left_ankle_y)), (255, 0, 255), 2)\n",
        "\n",
        "                cv2.line(frame, (int(left_hip_x), int(left_hip_y)), (int(left_ankle_x), int(left_ankle_y)), (0, 150, 255), 2)\n",
        "                cv2.line(frame, (int(left_hip_x), int(left_hip_y)), (int(right_shoulder_x), int(right_shoulder_y)), (0, 150, 255), 2)\n",
        "\n",
        "                cv2.line(frame, (int(left_shoulder_x), int(left_shoulder_y)), (int(left_elbow_x), int(left_elbow_y)), (128, 0, 128), 2)\n",
        "                cv2.line(frame, (int(left_elbow_x), int(left_elbow_y)), (int(left_wrist_x), int(left_wrist_y)), (128, 0, 128), 2)\n",
        "                cv2.line(frame, (int(midpoint_x), int(midpoint_y)), (int(midpoint_x), int(midpoint_y) - 200), (255, 255, 255), 2)\n",
        "\n",
        "                # Write coordinates to CSV file\n",
        "                if input == 'file':\n",
        "                  video_name = csv_file_name\n",
        "                else:\n",
        "                  if a == 0:\n",
        "                      video_name = filename.replace('.mp4', '')\n",
        "                  else:\n",
        "                      video_name = filename.replace('.mp4', f'_{a+1}')\n",
        "\n",
        "                write_csv_file(video_name, [video_timestamp, shoulders_inclination, hips_inclination,\n",
        "                                            knee_angle, pelvis_angle, arm_angle,\n",
        "                                            int(right_shoulder_x), int(right_shoulder_y),\n",
        "                                            int(left_shoulder_x), int(left_shoulder_y),\n",
        "                                            int(left_elbow_x), int(left_elbow_y),\n",
        "                                            int(right_wrist_x), int(right_wrist_y),\n",
        "                                            int(left_wrist_x), int(left_wrist_y),\n",
        "                                            int(nose_x), int(nose_y),\n",
        "                                            int(right_hip_x), int(right_hip_y),\n",
        "                                            int(left_hip_x), int(left_hip_y),\n",
        "                                            int(right_knee_x), int(right_knee_y),\n",
        "                                            int(left_knee_x), int(left_knee_y),\n",
        "                                            int(right_ankle_x), int(right_ankle_y),\n",
        "                                            int(left_ankle_x), int(left_ankle_y),\n",
        "                                            int(midpoint_x), int(midpoint_y)])\n",
        "\n",
        "                a = a+1\n",
        "\n",
        "            if a == 1:\n",
        "                cv2.putText(frame, f'Shoulders inclination: {shoulders_inclination:.2f}', (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "                cv2.putText(frame, f'Hips inclination: {hips_inclination:.2f}', (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "                cv2.putText(frame, f'Knee Angle: {knee_angle:.2f}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)\n",
        "                cv2.putText(frame, f'Pelvis Angle: {pelvis_angle:.2f}', (10, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 150, 255), 2)\n",
        "                cv2.putText(frame, f'Arm Angle: {arm_angle:.2f}', (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (128, 0, 128), 2)\n",
        "\n",
        "\n",
        "            frame = cv2.resize(frame, (int(cap.get(3)), int(cap.get(4))))\n",
        "            out.write(frame)\n",
        "        else:\n",
        "            break\n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "T5WMMjq0QDIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if input == 'file':\n",
        "  pose_estimation(input_file, csv_file_name, output_video_name)\n",
        "else:\n",
        "  for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        # Set output file names\n",
        "        csv_file_name = f'{os.path.splitext(filename)[0]}.csv'\n",
        "        output_video_name = f'{os.path.splitext(filename)[0]}_output.mp4'\n",
        "        csv_file_path = os.path.join(output_folder_csv, csv_file_name)\n",
        "        output_video_path = os.path.join(output_folder_videos, output_video_name)\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        pose_estimation(file_path, csv_file_path, output_video_path)"
      ],
      "metadata": {
        "id": "4qoRfnWcP4KJ",
        "outputId": "abe1a79b-b7fb-4140-cf2e-f4313c762158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    }
  ]
}