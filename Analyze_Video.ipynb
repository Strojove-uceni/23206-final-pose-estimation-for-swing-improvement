{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFhULSOfhJ/AJIet603OEz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/23206-final-pose-estimation-for-swing-improvement/blob/main/Analyze_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Swing Demo\n",
        "\n",
        "This demo shows the usage of swing analyzer we developed as a part of our project. It requires a video a golfer swinging from the front which is then analyzed and evaluated. This analysis should serve as a sort of 'virtual trainer' giving you information about the mistakes made in the swing to improve your technique. The output of our work is 3 frames detected in the video, which contain the main swing parts that are generally analyzed in golf. In these frames, body parts, angles and different positions are marked either red or green based on the set limits they should ideally be within."
      ],
      "metadata": {
        "id": "D-cYA7e4sCMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone our repository\n",
        "\n",
        "To use our model, first we need to clone our repository where the different classes and functions are."
      ],
      "metadata": {
        "id": "pF94MQW8unGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2AVlt7_r5Ma",
        "outputId": "978ba550-890c-42e4-883c-d0c43011060e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '23206-final-pose-estimation-for-swing-improvement'...\n",
            "remote: Enumerating objects: 4065, done.\u001b[K\n",
            "remote: Counting objects: 100% (1399/1399), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1207/1207), done.\u001b[K\n",
            "remote: Total 4065 (delta 385), reused 1195 (delta 192), pack-reused 2666\u001b[K\n",
            "Receiving objects: 100% (4065/4065), 1.40 GiB | 45.97 MiB/s, done.\n",
            "Resolving deltas: 100% (592/592), done.\n",
            "Updating files: 100% (1430/1430), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Strojove-uceni/23206-final-pose-estimation-for-swing-improvement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the model and evaluation functions"
      ],
      "metadata": {
        "id": "HkllLs9uw9bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "sys.path.append('/content/23206-final-pose-estimation-for-swing-improvement')\n",
        "from process_swing import DataProcessor, Evaluator, VideoProcessor"
      ],
      "metadata": {
        "id": "uhi-GPPVuyJg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the path to video"
      ],
      "metadata": {
        "id": "d9AAO0jPxKUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder path where your video and CSV files are located\n",
        "folder_path = 'test_classes'"
      ],
      "metadata": {
        "id": "FjotAUhnw35I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Using DataProcessor\n",
        "DataPreprocessor preprocesses the output of the model and keeps only information about the 3 frames that we are analyzing.\n"
      ],
      "metadata": {
        "id": "yP8Et_Dpxb8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_processor = DataProcessor(folder_path)\n",
        "data_processor.load_data()\n",
        "data_processor.preprocess_data()"
      ],
      "metadata": {
        "id": "iR5EaBNCvMuz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Evaluator\n",
        "Evaluator uses the preprocessed data to determine the correctness of the swing aspects. It gives binary values based on correctness."
      ],
      "metadata": {
        "id": "CKih9QgTx_Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = Evaluator(data_processor)\n",
        "evaluator.evaluate_all_swing_parts()\n"
      ],
      "metadata": {
        "id": "ik7HJc5kxW0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Instantiate and use VideoProcessor\n",
        "\n",
        "Finally the VideoProcessr writes the points, lines and angles into the video frames in the colors based on correctness given by the Evaluator."
      ],
      "metadata": {
        "id": "V9wjApWqyi4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_processor = VideoProcessor(folder_path, data_processor, evaluator)\n",
        "video_processor.save_frame()\n",
        "\n",
        "# At this point, the frames should be saved to the folder."
      ],
      "metadata": {
        "id": "8KbUgYVbxY8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "images = []\n",
        "\n",
        "# Define the keywords for sorting\n",
        "keywords = ['address', 'top', 'contact']\n",
        "\n",
        "# Function to extract the keyword index from the filename\n",
        "def extract_keyword_index(filename):\n",
        "    filename_lower = filename.lower()\n",
        "    for idx, keyword in enumerate(keywords):\n",
        "        if keyword in filename_lower:\n",
        "            return idx\n",
        "    return len(keywords)  # Assign a higher index if keyword not found\n",
        "\n",
        "# Sort the image files based on keywords\n",
        "sorted_image_files = sorted(image_files, key=lambda x: extract_keyword_index(x))\n",
        "\n",
        "# Create a list to hold all images\n",
        "images = []\n",
        "\n",
        "# Read each image and append it to the list\n",
        "for image_file in sorted_image_files:\n",
        "    image_path = os.path.join(folder_path, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    # Convert BGR to RGB format for display\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    images.append(image)\n",
        "\n",
        "# Create a figure to display the images\n",
        "num_images = len(images)\n",
        "fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "\n",
        "# Display each image in its respective subplot\n",
        "for i in range(num_images):\n",
        "    axes[i].imshow(images[i])\n",
        "    axes[i].set_title(f'{sorted_image_files[i].split(\"_\")[-1].split(\".\")[0]}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "# Show the images\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZX9oWkS78O9R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}